# ParquetFrame Development Continuation Roadmap

**Status**: ACTIVE DEVELOPMENT
**Last Updated**: 2025-01-15
**Current Version**: 0.5.0

## ğŸ¯ Development Strategy Overview

We're following a strategic development approach that builds on existing foundations before embarking on major new features:

1. **Phase 0**: Complete Partially Implemented Features (CURRENT)
2. **Phase 2**: Graph Engine Development (Next Major Feature)
3. **Phase 3**: Advanced Features & Enterprise Capabilities
4. **Phase 1**: Production Hardening & Cloud Integration

This order allows us to:

- âœ… Maximize return on existing investments
- ğŸ—ï¸ Strengthen core architecture before major additions
- ğŸš€ Deliver high-impact features with lower implementation risk
- ğŸ“ˆ Build momentum with incremental wins

---

## ğŸŸ¡ **PHASE 0: PARTIALLY IMPLEMENTED FEATURES** (CURRENT)

### **0.1 Multi-Format Support Enhancement**

**Status**: âœ… COMPLETED
**Priority**: HIGH
**Completed**: 2025-10-14
**Time Taken**: 1 week (faster than estimated)

#### Implementation Summary

- âœ… **Handler-Based Architecture**: Implemented extensible `IOHandler` pattern with format-specific classes
- âœ… **Format Detection**: Automatic format detection from file extensions with manual override support
- âœ… **Multi-Format Support**: CSV (.csv, .tsv), JSON (.json, .jsonl, .ndjson), ORC (.orc), Parquet (.parquet, .pqt)
- âœ… **Backend Integration**: All formats work with both pandas and Dask backends with intelligent selection
- âœ… **Path Resolution**: Enhanced file path resolution that checks exact paths before trying extensions
- âœ… **Comprehensive Testing**: 23 comprehensive tests covering all format handlers and edge cases

#### Key Features Implemented

- âœ… `ParquetFrame.read("data.csv")` - Automatic CSV format detection and reading
- âœ… `ParquetFrame.read("data.json")` - JSON and JSON Lines format support
- âœ… `ParquetFrame.read("file.txt", format="csv")` - Explicit format override
- âœ… File size-based backend selection (pandas vs Dask)
- âœ… Format-specific error handling with clear error messages
- âœ… TSV support with automatic delimiter detection
- âœ… ORC support with graceful pyarrow dependency handling

#### Technical Implementation

- âœ… **Files Modified**:
  - `src/parquetframe/core.py` - New `FileFormat` enum, `IOHandler` classes, updated `ParquetFrame.read()`
  - `tests/io/test_multiformat.py` - Comprehensive 23-test suite with 47% code coverage
- âœ… **Architecture Pattern**: Abstract base class with format-specific handlers
- âœ… **Backward Compatibility**: All existing parquet functionality preserved
- âœ… **Error Handling**: Specific ImportError handling for optional dependencies

#### Performance & Quality Metrics

- âœ… **Test Coverage**: 47% on core module (significant improvement)
- âœ… **Test Suite**: 23/23 tests passing
- âœ… **Code Quality**: All pre-commit hooks passing (Black, Ruff, etc.)
- âœ… **Backward Compatibility**: 100% maintained for existing usage patterns
- âœ… **Memory Efficiency**: Intelligent backend selection based on file size

#### Next Steps

- [ ] CLI integration for new formats
- [ ] Enhanced documentation and examples
- [ ] Performance benchmarking across formats

---

### **0.2 Enhanced SQL Method Integration**

**Status**: âœ… COMPLETED
**Priority**: MEDIUM
**Completed**: 2025-01-15
**Actual Time**: 2 weeks (as expected)
**Versions**: 0.4.0, 0.4.1, 0.4.2

#### Current State Analysis (2025-10-14)

**âœ… What Works Well:**
- SQL support exists via `sql.py` module with DuckDB integration
- `ParquetFrame.sql()` method is functional with clean API
- Complex queries work including JOINs, window functions, aggregations
- Good test coverage (15 SQL-specific tests covering edge cases)
- CLI SQL commands are well-integrated
- Error handling includes graceful DuckDB dependency management
- Warning system for Dask DataFrame computation

**âœ… Phase 0.2 Implementation Summary:**
- âœ… **Fluent SQL API**: Complete method chaining with `select()`, `where()`, `group_by()`, `order_by()`
- âœ… **Performance Optimization**: Query result caching and execution profiling implemented
- âœ… **Enhanced Metadata**: QueryResult dataclass with timing, memory usage tracking
- âœ… **Multi-Format Integration**: SQL operations work seamlessly across CSV, JSON, ORC, Parquet
- âœ… **Query Builder Utilities**: SQLBuilder class and parameterized queries
- âœ… **Advanced JOIN Operations**: Convenience methods and proper table aliasing
- âœ… **Comprehensive Testing**: 27 new tests covering all new functionality
- âœ… **Documentation**: 936-line SQL cookbook with real-world examples

#### Implementation Plan

**Days 1-2: Multi-Format SQL Integration**
- [ ] Extend SQL support to work seamlessly with all formats (CSV, JSON, ORC)
- [ ] Add format-aware SQL optimization hints
- [ ] Test SQL operations across different input formats
- [ ] Update SQL documentation with multi-format examples

**Days 3-4: Performance & Usability Enhancements**
- [ ] Add SQL query execution profiling and timing
- [ ] Implement result set metadata (execution time, rows affected)
- [ ] Add query result caching for repeated queries
- [ ] Enhance error messages with query context and suggestions
- [ ] Add SQL query validation with better feedback

**Days 5-6: Advanced Features**
- [ ] Add SQL query builder utilities for common patterns
- [ ] Implement fluent SQL chaining: `pf.select().where().groupby().sql()`
- [ ] Add support for parameterized queries with prepared statements
- [ ] Enhanced JOIN helpers for ParquetFrame combinations

**Day 7: Documentation & Integration**
- [ ] Create comprehensive SQL cookbook with multi-format examples
- [ ] Add SQL performance tuning guide
- [ ] Update examples with new multi-format SQL capabilities
- [ ] Test integration with AI queries (existing functionality)

#### Success Criteria

- [ ] SQL works seamlessly across all file formats (CSV, JSON, ORC, Parquet)
- [ ] Enhanced performance with query profiling and metadata
- [ ] Fluent SQL API with method chaining capabilities
- [ ] Comprehensive SQL cookbook with real-world examples
- [ ] 95%+ SQL test coverage maintained
- [ ] Query execution time improvements for large datasets

---

### **0.3 Advanced Analytics Features**

**Status**: âœ… COMPLETED
**Priority**: MEDIUM
**Completion Time**: 1 week (faster than estimated 2 weeks)
**Completed Date**: 2025-01-15
**Version**: v0.5.0

#### Implementation Summary

**âœ… Statistical Analysis Features:**
- âœ… `.stats` accessor with `StatsAccessor` class providing comprehensive statistical operations
- âœ… `describe_extended()` - Extended descriptive statistics beyond basic pandas describe()
- âœ… `correlation_matrix()` - Pearson, Spearman, and Kendall correlation analysis
- âœ… `distribution_summary()` - Distribution analysis with histogram and normality testing
- âœ… `detect_outliers()` - Multiple outlier detection methods (IQR, Z-score, Isolation Forest)
- âœ… `normality_test()` and `correlation_test()` - Statistical hypothesis testing
- âœ… `linear_regression()` - Simple and multiple linear regression analysis

**âœ… Time-Series Analysis Features:**
- âœ… `.ts` accessor with `TimeSeriesAccessor` class for temporal data operations
- âœ… `detect_datetime_columns()` - Automatic datetime column detection with multiple format support
- âœ… `parse_datetime()` - Flexible datetime parsing with format inference
- âœ… `resample()` - Time-based resampling with multiple aggregation methods
- âœ… `rolling()` - Rolling window operations (mean, std, sum, max, min, custom functions)
- âœ… `shift()`, `lag()`, `lead()` - Temporal data shifting for lag analysis
- âœ… `between_time()`, `at_time()` - Time-of-day filtering operations

**âœ… CLI Integration:**
- âœ… `pframe analyze` command for statistical analysis with correlation, outliers, regression options
- âœ… `pframe timeseries` command for time-series operations with resampling, rolling, shifting
- âœ… Rich terminal output with formatted results and save options

**âœ… Performance Optimizations:**
- âœ… LRU caching for expensive datetime detection and statistical computations
- âœ… Memory-aware operation selection with automatic chunking for large datasets
- âœ… Optimized Dask operations with efficient sampling and batch processing
- âœ… Progress warnings for large datasets and memory-intensive operations
- âœ… Chunked processing for statistical calculations on large pandas datasets

**âœ… Documentation & Testing:**
- âœ… Complete analytics guide (`docs/analytics.md`) with examples and best practices
- âœ… Dedicated time-series documentation (`docs/timeseries.md`) with workflow patterns
- âœ… 80+ comprehensive tests for statistical and time-series functionality
- âœ… Updated README with analytics examples and CLI reference

#### Key Technical Achievements

- âœ… **Backend Intelligence**: Automatic pandas/Dask selection for analytics operations
- âœ… **Memory Management**: Intelligent chunked processing for large datasets
- âœ… **Performance**: LRU caching and optimized batch operations
- âœ… **Type Safety**: Comprehensive type hints and error handling
- âœ… **Integration**: Seamless integration with existing CLI and SQL functionality

#### Files Created/Modified

- âœ… `src/parquetframe/timeseries.py` - New time-series analysis module (529 lines)
- âœ… `src/parquetframe/stats.py` - New statistical analysis module (800+ lines)
- âœ… `src/parquetframe/core.py` - Added `.ts` and `.stats` accessor properties
- âœ… `src/parquetframe/cli.py` - Added `pframe analyze` and `pframe timeseries` commands
- âœ… `tests/test_timeseries.py` - Comprehensive time-series test suite (19 tests)
- âœ… `tests/test_stats.py` - Comprehensive statistical test suite (28 tests)
- âœ… `docs/analytics.md` - Complete analytics documentation guide
- âœ… `docs/timeseries.md` - Dedicated time-series documentation

---

## ğŸ¯ **PHASE 1: GRAPH ENGINE DEVELOPMENT** (NEXT MAJOR PHASE)

### **1.1 Apache GraphAr Foundation**

**Status**: ğŸš§ IN PROGRESS
**Priority**: HIGH
**Estimated Time**: 4-6 weeks

#### Implementation Strategy

Based on detailed analysis in `CONTEXT_GRAPH.md`, implement:

- [x] GraphAr directory structure and metadata
- [x] Vertex and edge data organization
- [x] CSR/CSC adjacency list representations
- [x] Basic graph I/O operations (GraphArReader -> GraphFrame)

#### Key Deliverables

- [x] `pf.read_graph("my_social_graph/")` functionality
- [x] Graph data validation and schema checking
- [x] Basic vertex/edge property access
- [x] Foundation for graph algorithms (CSR/CSC ready)

#### Progress Update (2025-10-17)

Completed:
- Implemented `GraphFrame` with efficient degree/neighbor/has_edge methods using lazy CSR/CSC
- Added `VertexSet` and `EdgeSet` with schema/type validation and flexible column handling
- Implemented `GraphArReader` with metadata/schema validation and multi-type loading
- Added `CSRAdjacency` and `CSCAdjacency` with NumPy-backed sparse structures, subgraph extraction, and optional weights

Remaining for 1.1:
- [ ] CLI integration: `pf graph info <path>`, expose schema/summary in CLI
- [ ] Tests: unit/integration for GraphArReader, GraphFrame, CSR/CSC, VertexSet/EdgeSet (â‰¥45% coverage)
- [ ] Docs: `docs/graph/overview.md`, `docs/graph/usage.md` with examples
- [ ] PR: open, review, CI green, squash-merge

---

### **1.2 Graph Traversal Algorithms**

**Status**: ğŸ”„ PLANNED
**Priority**: HIGH
**Estimated Time**: 3-4 weeks

#### Core Algorithms to Implement

- [ ] Breadth-First Search (BFS) with Dask optimization
- [ ] Depth-First Search (DFS)
- [ ] Shortest path algorithms
- [ ] Connected components analysis
- [ ] PageRank implementation

---

### **1.3 Zanzibar-Style Permissions**

**Status**: ğŸ”„ PLANNED
**Priority**: MEDIUM
**Estimated Time**: 3-4 weeks

#### ReBAC Implementation

- [ ] Relation tuple modeling
- [ ] Check API implementation
- [ ] Expand API for complex permissions
- [ ] Performance optimization for large permission sets

---

## ğŸš€ **PHASE 2: ADVANCED FEATURES & ENTERPRISE**

### **3.1 Streaming Support**

**Status**: ğŸ”„ FUTURE
**Priority**: MEDIUM
**Estimated Time**: 4-6 weeks

#### Streaming Capabilities

- [ ] Kafka/Pulsar integration
- [ ] Real-time data ingestion
- [ ] Stream processing workflows
- [ ] Real-time analytics dashboard

---

### **2.2 Advanced Visualizations**

**Status**: ğŸ”„ FUTURE
**Priority**: MEDIUM
**Estimated Time**: 3-4 weeks

#### Visualization Framework

- [ ] Matplotlib/Plotly integration
- [ ] Interactive dashboard capabilities
- [ ] Export to visualization formats
- [ ] Graph visualization for pfg

---

## ğŸ­ **PHASE 1: PRODUCTION HARDENING** (FINAL PHASE)

### **3.1 Cloud Storage Integration**

**Status**: ğŸ”„ FUTURE
**Priority**: HIGH
**Estimated Time**: 3-4 weeks

#### Cloud Connectors

- [ ] AWS S3 integration with authentication
- [ ] Google Cloud Storage support
- [ ] Azure Blob Storage support
- [ ] Cloud-specific performance optimizations

---

### **3.2 Security & Enterprise Features**

**Status**: ğŸ”„ FUTURE
**Priority**: HIGH
**Estimated Time**: 4-6 weeks

#### Enterprise Capabilities

- [ ] Role-based access control
- [ ] Audit logging framework
- [ ] Data governance features
- [ ] Encryption at rest/in transit

---

## ğŸ“‹ **CURRENT SPRINT PLANNING**

### **Completed Sprint: Multi-Format Support (Phase 0.1)**

**Duration**: 1 week (completed faster than estimated)
**Start Date**: 2025-10-14
**Completion Date**: 2025-10-14

#### Sprint Results

1. âœ… **COMPLETED**: CSV format support with auto-detection and TSV support
2. âœ… **COMPLETED**: JSON format handling including JSON Lines format
3. âœ… **COMPLETED**: ORC format support with graceful dependency handling
4. âœ… **COMPLETED**: 47% test coverage with comprehensive 23-test suite
5. âœ… **COMPLETED**: Handler-based architecture for extensibility

#### Key Accomplishments

- **Architecture**: Implemented clean `IOHandler` pattern with format-specific classes
- **Testing**: 23/23 tests passing with comprehensive coverage of all formats
- **Backend Integration**: All formats work with both pandas and Dask
- **Error Handling**: Graceful handling of missing dependencies and file issues
- **Backward Compatibility**: 100% preserved for existing parquet functionality

### **Sprint Complete: CLI Integration & Documentation (Phase 0.1 Polish)**

**Duration**: 1 day (completed faster than estimated)
**Start Date**: 2025-10-14
**Completion Date**: 2025-10-14

#### Sprint Results

1. âœ… **COMPLETED**: CLI commands now work with all formats (CSV, JSON, ORC, Parquet)
2. âœ… **COMPLETED**: Comprehensive format documentation created
3. âœ… **COMPLETED**: Multi-format usage examples and cookbook entries added
4. [ ] Performance benchmarking across formats (moved to next phase)
5. âœ… **COMPLETED**: README and docs updated with multi-format examples

### **Active Sprint: Phase 1.1 GraphAr Foundation (Major Milestone)**

**Status**: ğŸš§ **IN PROGRESS**
**Duration**: 3 days active development (Oct 15-17, 2025)
**Start Date**: 2025-10-15
**Target Completion**: 2025-10-20
**Branch**: `feature/graph-engine-phase1.1-graphar`

#### Sprint Progress: 70% Complete

**âœ… COMPLETED (Core Engine - 7/11 tasks):**
1. âœ… Repository reconnaissance & environment bootstrap
2. âœ… Feature branch creation with tracking
3. âœ… Public API surface definition (GraphFrame, read_graph)
4. âœ… GraphAr directory & schema validation (GraphArReader)
5. âœ… Vertex & edge parquet loading utilities (VertexSet, EdgeSet)
6. âœ… Adjacency list creation (CSRAdjacency, CSCAdjacency)
7. âœ… GraphFrame core object with efficient operations

**ğŸ”„ REMAINING (Polish Phase - 4/11 tasks):**
8. [ ] CLI integration (`pf graph info <path>`, schema summary)
9. [ ] Testing & coverage â‰¥45% (unit/integration test suite)
10. [ ] Documentation (MkDocs pages with examples)
11. [ ] Pull request & branch cleanup

#### Technical Achievements (Major Milestone)

**ğŸ—ï¸ Graph Processing Engine:**
- **GraphFrame**: Complete graph object with lazy CSR/CSC adjacency
- **CSRAdjacency/CSCAdjacency**: NumPy-backed O(V+E) sparse structures
- **VertexSet/EdgeSet**: Schema-validated data with flexible column naming
- **GraphArReader**: Apache GraphAr compliance with metadata validation

**âš¡ Performance Features:**
- O(degree) neighbor/predecessor lookups for sparse graphs
- Lazy adjacency loading with memory-efficient representations
- Pandas/Dask backend selection with automatic conversion warnings
- Subgraph extraction preserving adjacency structure

**ğŸ”§ Integration & Quality:**
- Seamless ParquetFrame ecosystem integration
- Comprehensive error handling with descriptive messages
- 100% linting compliance (Black, Ruff) across 1,700+ lines
- Type-safe implementations with full docstring coverage

#### Files Created/Modified

**New Modules:**
- `src/parquetframe/graph/__init__.py` - GraphFrame API (305 lines)
- `src/parquetframe/graph/data.py` - VertexSet/EdgeSet classes (485 lines)
- `src/parquetframe/graph/adjacency.py` - CSR/CSC structures (573 lines)
- `src/parquetframe/graph/io/graphar.py` - GraphAr reader (467 lines)
- `src/parquetframe/graph/io/__init__.py` - I/O module interface

**Enhanced Modules:**
- `src/parquetframe/__init__.py` - Added graph module exposure

#### Next Development Phase

**Current Focus**: Polish & finalization for Phase 1.1
**Immediate Next**: CLI integration with `pf graph` commands
**After 1.1**: Phase 1.2 Graph Traversal Algorithms (BFS, DFS, shortest paths)

### **Phase 0.1 Multi-Format Support - COMPLETION SUMMARY**

**Status**: âœ… **FULLY COMPLETED**
**Duration**: 1 day total (significantly faster than 2-3 week estimate)
**Date**: 2025-10-14
**Version**: 0.3.2

#### Final Deliverables Achieved

- âœ… **Core Implementation**: Handler-based multi-format architecture
- âœ… **Format Support**: CSV, TSV, JSON, JSON Lines, NDJSON, Parquet, ORC
- âœ… **Automatic Detection**: Smart format detection from file extensions
- âœ… **Manual Override**: `--format` option for explicit format specification
- âœ… **Backend Intelligence**: File size-based pandas/Dask selection (100MB threshold)
- âœ… **CLI Integration**: Full multi-format support in `pframe run` and `pframe info` commands
- âœ… **Comprehensive Testing**: 382/383 tests passing (99.7% success rate)
- âœ… **Documentation**: Complete format guide, examples, and README updates
- âœ… **Error Handling**: Graceful dependency management and format validation
- âœ… **Backward Compatibility**: 100% maintained for existing parquet workflows
- âœ… **Cross-Platform Compatibility**: Windows, macOS, and Linux support
- âœ… **Test Coverage**: 57% overall code coverage (exceeds 40% requirement)

### **Phase 0.1.1 Windows Compatibility & Bug Fixes**

**Status**: âœ… **COMPLETED**
**Duration**: 1 day
**Date**: 2025-10-14
**Version**: 0.3.2

#### Issues Resolved

- âœ… **Windows CI/CD Pipeline**: Fixed ArrowException timezone database errors on Windows
- âœ… **File Permission Errors**: Resolved Windows file locking issues during test cleanup
- âœ… **Test Suite Compatibility**: 382/383 tests now pass across all platforms
- âœ… **ORC Format Handling**: Graceful ORC test skipping on Windows due to Arrow limitations
- âœ… **Temporary File Management**: Robust cleanup with retry logic and garbage collection
- âœ… **Cross-Platform Testing**: Enhanced test fixtures for Windows compatibility

#### Technical Improvements

- âœ… **Windows-Specific Error Handling**: Platform detection and graceful degradation
- âœ… **File Handle Management**: Proper cleanup with garbage collection on Windows
- âœ… **Retry Logic**: 3-attempt cleanup with progressive permission fixes
- âœ… **Test Infrastructure**: Windows-compatible temporary directory fixtures
- âœ… **Platform Detection**: `os.name == 'nt'` checks for Windows-specific behavior

#### Version History

- **v0.3.0**: Initial multi-format support release
- **v0.3.1**: Test fixes and directory handling improvements
- **v0.3.2**: Windows compatibility and CI/CD pipeline fixes

---

## ğŸ¯ **SUCCESS METRICS & MILESTONES**

### **Phase 0 Completion Criteria**

- âœ… Support for CSV, JSON, ORC formats with auto-detection (v0.3.2)
- [ ] Enhanced SQL API consistency across library/CLI
- [ ] Basic time-series and advanced analytics capabilities
- âœ… Test coverage >55% overall (achieved: 57%)
- âœ… Documentation updated for all new features (comprehensive)

### **Phase 1 Completion Criteria**

- [x] Functional graph processing engine (pfg) â€” foundation implemented (GraphAr + CSR/CSC)
- [ ] Core graph algorithms (BFS, DFS, shortest path)
- [ ] Basic Zanzibar-style permission checking
- [ ] Graph CLI commands and examples

### **Phase 2 Completion Criteria**

- [ ] Streaming data processing capabilities
- [ ] Integrated visualization framework
- [ ] Advanced enterprise features
- [ ] Comprehensive performance benchmarking

### **Phase 3 Completion Criteria**

- [ ] Full cloud storage integration (S3, GCS, Azure)
- [ ] Enterprise security and governance features
- [ ] Production-ready deployment guides
- [ ] Scalability testing and optimization

---

## ğŸ”§ **DEVELOPMENT STANDARDS**

### **Git Workflow**

- ğŸŒ¿ **Branching**: `feature/phase0-multiformat-support`
- ğŸ“ **Commits**: Conventional commits (feat:, fix:, docs:, test:)
- ğŸ”„ **PRs**: Feature branch â†’ main with review process
- ğŸ·ï¸ **Versioning**: Semantic versioning for releases

### **Testing Requirements**

- ğŸ§ª **Coverage**: Maintain >45% minimum, target 70%+
- âœ… **Quality**: All new features require comprehensive tests
- ğŸ”„ **CI/CD**: All tests must pass before merge
- ğŸ“Š **Performance**: Benchmark tests for major features

### **Code Quality**

- ğŸ” **Linting**: Ruff, Black, MyPy compliance required
- ğŸ“š **Documentation**: Docstrings and examples for all public APIs
- ğŸ—ï¸ **Architecture**: Maintain dependency injection patterns
- ğŸ” **Security**: Security review for enterprise features

---

## ğŸ“ˆ **PROGRESS TRACKING**

### **Phase 0 Progress**

- âœ… 0.1 Multi-Format Support: 100% complete (2025-10-14) - v0.3.2
- [ ] 0.2 Enhanced SQL Method: 0% complete (NEXT)
- [ ] 0.3 Advanced Analytics: 0% complete

### **Phase 1 Progress**

- ğŸŸ¢ 1.1 GraphAr Foundation: 70% complete (Reader, GraphFrame, Vertex/Edge sets, CSR/CSC done)
- [ ] 1.2 Graph Traversal Algorithms: 0% complete
- [ ] 1.3 Zanzibar-Style Permissions: 0% complete

### **Overall Roadmap Progress**

- âœ… **Completed Features**: 32/37 (86%)
- ğŸŸ¡ **In Progress**: Phase 0 (2 remaining features)
- ğŸ“‹ **Planned**: Phases 1-3 (Major features)
- ğŸ¯ **Next Milestone**: Enhanced SQL Method Integration
- ğŸ† **Recent Achievement**: Cross-platform multi-format support with 57% test coverage

---

## ğŸ“ **COMMUNICATION & UPDATES**

### **Progress Updates**

This document will be updated after each major milestone with:

- âœ… Completed tasks and lessons learned
- ğŸ”„ Current progress and blockers
- ğŸ“‹ Next sprint planning and priorities
- ğŸ“Š Metrics and performance improvements

### **Decision Log**

Major technical decisions and their rationale will be documented here as we progress through the development phases.

---

**Last Updated**: 2025-10-17
**Next Update**: After completing Phase 1.1 CLI, tests, and docs
**Status**: ğŸš§ Phase 1.1 in progress â€” core graph engine implemented; polishing (CLI/tests/docs) remaining
